좋습니다! GitHub Actions를 사용하여 스크립트를 자동 실행하는 방법을 차근차근 안내해 드리겠습니다.

1단계: 사전 준비

GitHub 계정: GitHub 계정이 없다면 먼저 생성해 주세요.

프로젝트 파일:

chp2.py

signals.py

sb.json (Google API 키 파일) - 이 파일은 GitHub에 직접 올리지 않습니다!

Git 설치: 로컬 컴퓨터에 Git이 설치되어 있어야 합니다. (설치되어 있지 않다면 여기서 다운로드 및 설치)

2단계: 로컬 프로젝트 준비 및 GitHub 저장소 생성/연동

프로젝트 폴더 생성: 컴퓨터에 이 프로젝트만을 위한 새 폴더를 만듭니다. (예: market_scraper_project)

파일 복사: 해당 폴더에 chp2.py와 signals.py 파일을 복사합니다.

.gitignore 파일 생성:

프로젝트 폴더(market_scraper_project) 안에 .gitignore 라는 이름의 파일을 만듭니다.

파일 내용은 다음과 같이 작성합니다. (이렇게 하면 민감한 파일이나 불필요한 파일이 GitHub에 올라가는 것을 방지합니다.)

# Google API Key
sb.json
*.json # 혹시 다른 json 키 파일이 있다면

# Python cache
__pycache__/
*.pyc
*.pyo
*.pyd

# Virtual environment
.venv/
venv/
ENV/
env/
pip-selfcheck.json

# IDE/Editor specific
.idea/
.vscode/

# Excel files (GitHub Actions에서 생성 후 Sheets로 업로드하므로 저장소에 보관할 필요 없음)
*.xlsx


requirements.txt 파일 생성:

이 파일에는 스크립트 실행에 필요한 모든 Python 라이브러리가 명시됩니다.

프로젝트 폴더에서 터미널(명령 프롬프트 또는 PowerShell)을 열고 다음 명령어를 실행하여 현재 환경에 설치된 라이브러리 목록을 만듭니다. (가상환경을 사용하고 있다면 가상환경 활성화 후 실행)

pip freeze > requirements.txt
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Bash
IGNORE_WHEN_COPYING_END

requirements.txt 파일을 열어보고, 스크립트에 실제로 필요한 라이브러리들만 남겨두는 것이 좋습니다. (예: pandas, selenium, webdriver-manager-chrome (또는 webdriver-manager), yfinance, gspread, google-auth, google-auth-oauthlib, google-auth-httplib2, gspread-dataframe, openpyxl)

주의: webdriver-manager가 설치되어 있다면 webdriver-manager-chrome은 따로 필요 없을 수 있습니다. 둘 중 하나 또는 webdriver-manager만 명시하세요.

google-oauth2-service-account 대신 google-auth, google-auth-oauthlib, google-auth-httplib2가 필요할 수 있습니다. gspread가 의존하는 라이브러리를 확인하세요. 일반적으로 gspread와 google-auth 정도면 됩니다.

GitHub에 새 저장소(Repository) 생성:

GitHub 웹사이트로 이동하여 로그인합니다.

오른쪽 상단 '+' 아이콘 클릭 후 "New repository" 선택.

Repository name 입력 (예: market-data-scraper).

Public 또는 Private 선택 (Public은 무료 사용량 제한이 더 넉넉하지만, 코드가 공개됩니다. Private도 월 2000분의 무료 Actions 시간이 제공됩니다).

"Create repository" 클릭.

로컬 프로젝트를 GitHub 저장소에 연결하고 파일 올리기:

프로젝트 폴더에서 터미널을 엽니다.

다음 Git 명령어들을 순서대로 입력합니다.

git init
git add .
git commit -m "Initial commit of scraper project"
# 아래 <your-username>과 <repository-name>을 실제 정보로 바꾸세요.
git remote add origin https://github.com/<your-username>/<repository-name>.git
git branch -M main # 기본 브랜치 이름을 main으로 (master일 수도 있음)
git push -u origin main
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Bash
IGNORE_WHEN_COPYING_END

이제 GitHub 저장소에 chp2.py, signals.py, .gitignore, requirements.txt 파일이 올라갔을 것입니다. (sb.json은 .gitignore 때문에 올라가지 않았어야 정상입니다.)

3단계: chp2.py 스크립트 수정 (GitHub Actions 환경에 맞게)

Google API 키 파일 경로 수정:

chp2.py 파일을 열어서 GOOGLE_API_KEY_FILE 변수를 수정합니다. GitHub Actions에서는 Secret을 파일로 만들 것이므로, 상대 경로로 지정합니다.

# 기존 코드
# GOOGLE_API_KEY_FILE = r"C:\Users\masri\OneDrive\바탕 화면\GG download\sb.json"

# 변경 후 코드 (GitHub Actions에서 생성될 파일명)
GOOGLE_API_KEY_FILE = "sb.json"
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Python
IGNORE_WHEN_COPYING_END

Selenium WebDriver 옵션 추가 (Headless 모드):

GitHub Actions 환경에는 실제 화면(Display)이 없으므로, 브라우저를 화면 없이 실행하는 "Headless" 모드로 설정해야 합니다.

chp2.py 파일의 main_crawler 함수 내에서 WebDriver를 초기화하는 부분을 다음과 같이 수정합니다.

# main_crawler 함수 내
from selenium.webdriver.chrome.options import Options # 상단에 import 추가

# ... 기존 코드 ...
# 크롬 드라이버 실행
# driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())) # 기존 코드

# 변경 후 코드
chrome_options = Options()
chrome_options.add_argument("--headless")  # Headless 모드 활성화
chrome_options.add_argument("--no-sandbox") # Linux/Docker 환경에서 필요할 수 있음
chrome_options.add_argument("--disable-dev-shm-usage") # 리소스 제한적인 환경에서 필요
chrome_options.add_argument("--window-size=1920,1080") # 가상 윈도우 크기 (선택 사항)
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)
# ... 나머지 코드 동일 ...
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Python
IGNORE_WHEN_COPYING_END

파일 저장 경로 확인:

스크립트에서 엑셀 파일을 저장하는 부분 (f"market_data_report_{today_str}.xlsx")은 현재 작업 디렉터리에 저장됩니다. GitHub Actions에서는 이것이 임시 공간이며, 작업이 끝나면 사라집니다. Google Sheets로 업로드하는 것이 주 목적이므로 이 부분은 괜찮습니다.

수정된 chp2.py 파일을 GitHub에 다시 올립니다:

터미널에서 프로젝트 폴더로 이동한 뒤 다음 명령어를 실행합니다.

git add chp2.py
git commit -m "Update chp2.py for GitHub Actions (headless mode, API key path)"
git push origin main
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Bash
IGNORE_WHEN_COPYING_END

4단계: GitHub Secrets 설정 (Google API 키)

GitHub 저장소로 이동합니다.

상단 탭에서 "Settings"를 클릭합니다.

왼쪽 메뉴에서 "Secrets and variables" > "Actions"를 선택합니다.

"New repository secret" 버튼을 클릭합니다.

Name: GOOGLE_CREDENTIALS 라고 입력합니다. (이 이름은 나중에 Workflow 파일에서 사용됩니다.)

Secret: 로컬 컴퓨터에 있는 sb.json 파일을 텍스트 편집기로 열어서 파일의 전체 내용을 복사한 뒤, GitHub의 "Secret" 입력 칸에 붙여넣기 합니다.

// sb.json 파일 내용 예시 (실제로는 훨씬 김)
{
  "type": "service_account",
  "project_id": "your-project-id",
  "private_key_id": "your-private-key-id",
  // ... (중략) ...
  "private_key": "-----BEGIN PRIVATE KEY-----\nYOUR_PRIVATE_KEY_CONTENT\n-----END PRIVATE KEY-----\n",
  // ... (중략) ...
}
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Json
IGNORE_WHEN_COPYING_END

"Add secret" 버튼을 클릭합니다.

5단계: GitHub Actions Workflow 파일 생성

로컬 프로젝트 폴더에 .github/workflows 폴더 생성:

프로젝트의 최상위 폴더(market_scraper_project) 안에 .github 라는 폴더를 만듭니다.

.github 폴더 안에 workflows 라는 폴더를 또 만듭니다.

경로: market_scraper_project/.github/workflows/

Workflow YAML 파일 생성:

workflows 폴더 안에 main.yml (또는 원하는 이름, 예: scraper_schedule.yml) 파일을 만듭니다.

main.yml 파일에 다음 내용을 작성합니다.

name: Run Market Data Scraper and Upload

on:
  schedule:
    # 매일 두 번 실행 (UTC 기준). 원하는 시간으로 변경하세요.
    # 예: 한국 시간 오전 9시, 오후 9시 -> UTC 00:00, 12:00
    - cron: '0 0,12 * * *'
    # 예: 한국 시간 오전 8시, 오후 8시 -> UTC 23:00 (전날), 11:00
    # - cron: '0 23 * * *' # 전날 23시 (KST 오전 8시)
    # - cron: '0 11 * * *' # 당일 11시 (KST 오후 8시)
  workflow_dispatch: # GitHub Actions 탭에서 수동으로 실행할 수 있게 함

jobs:
  scrape_and_upload:
    runs-on: ubuntu-latest # 실행 환경 (Linux)
    steps:
      - name: Checkout repository content
        uses: actions/checkout@v4 # 저장소의 코드를 가져옴

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9' # 스크립트와 호환되는 Python 버전 명시

      - name: Install Google Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Create Google Credentials File from Secret
        run: echo "${{ secrets.GOOGLE_CREDENTIALS }}" > sb.json
        # GOOGLE_CREDENTIALS라는 Secret의 내용을 sb.json 파일로 저장

      - name: Run Python script
        env:
          PYTHONIOENCODING: "UTF-8" # 한글 출력 관련 설정 (필요시)
        run: python chp2.py

      - name: Clean up Google Credentials File # 보안을 위해 작업 후 키 파일 삭제
        if: always() # 이전 단계 성공/실패 여부와 관계없이 항상 실행
        run: rm -f sb.json
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Yaml
IGNORE_WHEN_COPYING_END

main.yml 파일을 GitHub에 올립니다:

터미널에서 프로젝트 폴더로 이동한 뒤 다음 명령어를 실행합니다.

git add .github/workflows/main.yml
git commit -m "Add GitHub Actions workflow for scheduled scraping"
git push origin main
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Bash
IGNORE_WHEN_COPYING_END

6단계: GitHub Actions 실행 확인 및 디버깅

GitHub 저장소로 이동합니다.

상단 탭에서 "Actions"를 클릭합니다.

왼쪽 메뉴에서 "Run Market Data Scraper and Upload" (또는 main.yml에서 name에 지정한 이름) 워크플로우를 선택합니다.

workflow_dispatch를 설정했기 때문에, "Run workflow" 버튼을 눌러 수동으로 테스트 실행해 볼 수 있습니다. (기본 브랜치 main 선택 후 실행)

실행이 시작되면 진행 상황과 각 단계의 로그를 실시간으로 볼 수 있습니다.

녹색 체크 표시는 성공, 빨간색 X 표시는 실패입니다.

실패 시, 해당 단계를 클릭하여 로그를 자세히 보면 오류의 원인을 파악할 수 있습니다.

스케줄 실행 확인: 설정한 cron 시간에 맞춰 자동으로 실행되는지 며칠 지켜봅니다.

중요: Cron 시간 설정

cron: '0 0,12 * * *' 는 UTC(협정 세계시) 기준입니다.

한국 시간(KST, UTC+9)으로 오전 9시, 오후 9시에 실행하고 싶다면 UTC로는 00:00, 12:00가 맞습니다.

만약 KST 오전 8시, 오후 8시에 실행하고 싶다면, UTC로는 전날 23:00, 당일 11:00가 됩니다.

cron: '0 23 * * *' (KST 오전 8시)

cron: '0 11 * * *' (KST 오후 8시)

두 개를 같이 쓰려면 워크플로우를 두 개 만들거나, 하나의 워크플로우에서 cron 항목을 두 줄로 추가할 수 있습니다.

on:
  schedule:
    - cron: '0 23 * * *'
    - cron: '0 11 * * *'
  workflow_dispatch:
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
Yaml
IGNORE_WHEN_COPYING_END

문제 해결 팁:

오류 로그 확인: Actions 탭에서 실행 로그를 자세히 보면 대부분의 문제 원인을 찾을 수 있습니다.

requirements.txt: 필요한 라이브러리가 모두 포함되었는지, 버전 충돌은 없는지 확인합니다.

파일 경로: 스크립트 내에서 파일/폴더 경로가 올바르게 참조되는지 확인합니다. GitHub Actions는 Linux 환경에서 실행됩니다.

Selenium 버전 & ChromeDriver: webdriver-manager가 대부분 자동으로 처리하지만, 간혹 Chrome 버전과 ChromeDriver 버전이 맞지 않아 문제가 생길 수 있습니다. 로그를 잘 살펴보세요.

Secret 이름: Workflow 파일(main.yml)에서 secrets.GOOGLE_CREDENTIALS 부분이 GitHub Secret 설정 시 사용한 이름과 정확히 일치하는지 확인합니다.

이제 GitHub Actions가 설정한 스케줄에 따라 자동으로 chp2.py 스크립트를 실행하여 데이터를 크롤링하고 Google Sheets에 업로드할 것입니다. 초기 설정이 조금 복잡해 보일 수 있지만, 한번 설정해두면 매우 편리합니다!